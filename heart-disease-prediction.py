# -*- coding: utf-8 -*-
"""Trabalho_IA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/159eLvSfD2dguUGXTqvUNICcIDzGX_dq5

# Guilherme Fontana e Lucas Klug
#### Universidade de Caxias do Sul
#### Fundamentos de Inteligência Artificial

##Tratamento dos dados

####Importação das bibliotecas
"""

from sklearn import metrics, neighbors, datasets, tree
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz, export_text
from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import mean_squared_error,mean_absolute_error
from sklearn.naive_bayes import GaussianNB, BernoulliNB
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sb
from imblearn.over_sampling import SMOTE
from google.colab import files, drive
from graphviz import Source

"""#### Leitura e tratamento dos dados"""

#arquivo = files.upload()
#file = pd.read_csv('heart.csv')

#https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction
file = pd.read_csv('/heart.csv')
file.head()

data = file.copy()

def index_of_dic(dic, key):
    return dic[key]

def StrList_to_UniqueIndexList(lista):
    group = set(lista)

    dic = {}
    i = 0
    for g in group:
        if g not in dic:
            dic[g] = i
            i += 1

    return [index_of_dic(dic, p) for p in lista]


data['Sex'] = StrList_to_UniqueIndexList(data['Sex'])
data['ChestPainType'] = StrList_to_UniqueIndexList(data['ChestPainType'])
data['RestingECG'] = StrList_to_UniqueIndexList(data['RestingECG'])
data['ExerciseAngina'] = StrList_to_UniqueIndexList(data['ExerciseAngina'])
data['ST_Slope'] = StrList_to_UniqueIndexList(data['ST_Slope'])

display(data.head(5))

heart_cols = ['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope', 'HeartDisease']

X = data.values[:, :11]
y = data.values[:, 11]

"""#### Balanceamento de Classes - Método SMOTE
##### Os modelos gerados a seguir utilizam o balanceamento SMOTE.

"""

#Dados antes do balanceamento
print(pd.DataFrame(X, y))

sm = SMOTE(random_state=73, k_neighbors = 4)
X, y = sm.fit_resample(X, y)
#Dados depois do balanceamento
print(pd.DataFrame(X, y))

"""#### Normalização dos dados - Método MinMaxScaler"""

#Dados antes da normalização
print(X)

normaliza = MinMaxScaler()
X=normaliza.fit_transform(X)
#Dados depois da normalização
print(X)

"""## Arvore de Decisão

#### Construção do objeto da classe Árvore de Decisão
"""

tree = DecisionTreeClassifier(max_depth = 5)
tree.fit(X,y)

#Aplicação do GridSearchCV
tree_para = {'criterion':['entropy','gini'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150],'min_samples_leaf':[1,2,3,4,5]}
grid = GridSearchCV(tree, tree_para, cv=5)
grid.fit(X, y)

best_clf = grid.best_estimator_
print(best_clf)

plot_tree(best_clf, filled=True)
plt.show()

print(export_text(best_clf))

"""#### Criação de conjuntos de treino e teste
#### Método de amostragem HoldOut
"""

#Criação de conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)

#Treino com dados de treino
best_clf=best_clf.fit(X_train, y_train)

#Armazena as predicões
predictions_train = best_clf.predict(X_test)

#Gera a matriz de confusão
confusion_matrix(y_test,predictions_train)

#Gera a matriz de confusão do treino na visualização de HeatMMap
cf = confusion_matrix(y_test,predictions_train)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Blues", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Cálculo da acurácia com dados de teste
accuracy_score(y_test,predictions_train)*100

#Métrica de avaliação por classe
print(classification_report(y_test,predictions_train,zero_division=0))

"""#### Método de amostragem Cross-Validation"""

#Armazena as predicões
predictions = cross_val_predict(best_clf,X,y,cv=10)

cf = confusion_matrix(y,predictions)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Greens", fmt="d",xticklabels=lbl1,yticklabels=lbl2) # Mostra grafico

#Cálculo da acurácia
print(accuracy_score(y,predictions)*100)

#Métrica de avaliação por classe
print(classification_report(y,predictions,zero_division=0))

"""#### Classificação Binária
#### AUC (Area Under Curve)

"""

false_positive_rate, true_positive_rate, thresholds = roc_curve(y, predictions)
roc_auc = auc(false_positive_rate, true_positive_rate)
print(roc_auc)

"""##KNN

#### Aplicação do método GridSearchCV
"""

#GridSearchCV
classificadorKnn = KNeighborsClassifier()
params = {'n_neighbors':[1,3,5,7,9],'weights':['uniform','distance'],'metric':['euclidean','minkowski','manhattan']}
grid = GridSearchCV(classificadorKnn, params)
grid_search=grid.fit(X, y)

best_clf = grid.best_estimator_
print(best_clf)

"""####Criação de conjuntos de treino e teste
#### Método de amostragem HoldOut
"""

#Criação de conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)

#ClassificadorNeigh
ClassificadorNeigh=best_clf.fit(X_train, y_train)

#Armazena as predicões
predictions_train = ClassificadorNeigh.predict(X_test)

#Gera a matriz de confusão
confusion_matrix(y_test,predictions_train)

#Gera a matriz de confusão do treino na visualização de HeatMMap
cf = confusion_matrix(y_test,predictions_train)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Blues", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Cálculo da acurácia com dados de teste
accuracy_score(y_test,predictions_train)*100

#Métrica de avaliação por classe
print(classification_report(y_test,predictions_train,zero_division=0))

"""#### Método de amostragem Cross-Validation"""

#Cross Validation
predictions_train2 = cross_val_predict(best_clf,X,y)

#Gera a matriz de confusão dos dados de treino
confusion_matrix(y,predictions_train2)

#Gera a matriz de confusão do treino na visualização de HeatMMap
cf = confusion_matrix(y,predictions_train2)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Reds", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Cálculo da acurácia com dados de teste
accuracy_score(y,predictions_train2)*100

#Métrica de avaliação por classe
print(classification_report(y,predictions_train2,zero_division=0))

"""## Redes Bayesianas

### Modelo Gaussiano
"""

gnb = GaussianNB()
params = {'var_smoothing': [1e-9, 1e-6, 1e-12]}

gaussian_nb_grid = GridSearchCV(gnb, param_grid=params, n_jobs=-1, cv=5, verbose=5)
gaussian_nb_grid.fit(X,y)

"""#### Criação de conjuntos de treino e teste
#### Método de amostragem HoldOut
"""

#Criacao de conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)

gnb=gaussian_nb_grid.fit(X_train, y_train)

#Armazena as predicões
predictions_train = gnb.predict(X_test)

#Gera a matriz de confusão do treino
confusion_matrix(y_test,predictions_train)

#Gera a matriz de confusão do treino na visualização de HeatMMap
cf = confusion_matrix(y_test,predictions_train)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Blues", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Cálculo da acurácia com dados de teste
accuracy_score(y_test,predictions_train)*100

#Métrica de avaliação por classe
print(classification_report(y_test,predictions_train,zero_division=0))

"""
#### Método de amostragem Cross-Validation
"""

#Cross Validation
predictions = cross_val_predict(gnb,X,y,cv=5)

#Gera a matriz de confusão do treino
print(confusion_matrix(y,predictions))

cf = confusion_matrix(y,predictions)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="ocean", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Calcula acurácia do treino
accuracy_score(y,predictions)*100

#Métrica de avaliação por classe
print(classification_report(y,predictions,zero_division=0))

"""### Modelo de Bernoulli"""

gnbB = BernoulliNB()
params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],
          'fit_prior': [True, False],
          'class_prior': [None, [0.1,]* 2, ],
          'binarize': [None, 0.0, 8.5, 10.0]
         }

bernoulli_nb_grid = GridSearchCV(gnbB, param_grid=params, n_jobs=-1, cv=5, verbose=5)
bernoulli_nb_grid.fit(X,y)

bernoulli_nb_grid = bernoulli_nb_grid.best_estimator_

"""#### Criação de conjuntos de treino e teste
#### Método de amostragem HoldOut
"""

#Criacao de conjuntos de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=100)
print (X_train.shape, y_train.shape)
print (X_test.shape, y_test.shape)

bernoulli_nb_grid=bernoulli_nb_grid.fit(X_train, y_train)

#Armazena as predicões
predictions_train = bernoulli_nb_grid.predict(X_test)

#Gera a matriz de confusão do treino
confusion_matrix(y_test,predictions_train)

#Gera a matriz de confusão do treino na visualização de HeatMMap
cf = confusion_matrix(y_test,predictions_train)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="Blues", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Cálculo da acurácia com dados de teste
accuracy_score(y_test,predictions_train)*100

#Métrica de avaliação por classe
print(classification_report(y_test,predictions_train,zero_division=0))

"""
#### Método de amostragem Cross Validation
"""

#Cross Validation
predictions = cross_val_predict(bernoulli_nb_grid,X,y,cv=5)

print(confusion_matrix(y,predictions))
print(classification_report(y,predictions,zero_division=0))

cf = confusion_matrix(y,predictions)
lbl1=['Not heart disease', 'Heart disease']
lbl2 = ['Not heart disease', 'Heart disease']
sb.heatmap(cf,annot=True,cmap="ocean", fmt="d",xticklabels=lbl1,yticklabels=lbl2)

#Calcula acurácia do treino
accuracy_score(y,predictions)*100

#Métrica de avaliação por classe
print(classification_report(y,predictions,zero_division=0))